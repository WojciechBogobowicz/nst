{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import sewar.full_ref\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import src.model\n",
    "import src.selectioner\n",
    "import src.utils\n",
    "import src.vizualization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to use different images in training, put them into `./images/contents` and `./images/styles` folders and change `style_image_file` and `content_image_file` variables to appropriate values.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_image_file = \"demo_picasso_music.jpg\"\n",
    "content_image_file = \"demo_pablo_picasso.jpg\"\n",
    "\n",
    "BASE_RESULT_PATH = os.path.join(\"images\", \"results\")\n",
    "BASE_TRAINER_PATH = os.path.join(\"images\", \"trainers\")\n",
    "\n",
    "style_image_path = os.path.join(\"images\", \"styles\", style_image_file)\n",
    "content_image_path = os.path.join(\"images\", \"contents\", content_image_file)\n",
    "\n",
    "style_image = src.utils.tf_utils.load_img(style_image_path)\n",
    "content_image = src.utils.tf_utils.load_img(content_image_path)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create 16 random `NSTImageTrainer`. Each of them is responsible for generating one image. All input images are the same, but because of differences in trainers initializations images generated by them should be slightly different. All trainers share the same VGG backbone model, so you don't have to worry about running out of the RAM.  \n",
    "- Trainers are created from layers selectors, which means provided functions will pick layers that will capture style and content for you.  \n",
    "- Selectors used in this code pick layers randomly with specified weights. You can modify them or write your own in [./src/utils/randomizers.py](./src/utils/randomizers.py) file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainers= []\n",
    "trainers_num = 16\n",
    "\n",
    "for _ in tqdm(range(trainers_num)):\n",
    "    trainer = src.model.NSTImageTrainer.from_layers_selectors(\n",
    "            style_image,\n",
    "            content_image,\n",
    "            src.utils.randomizers.random_length_choices,\n",
    "            src.utils.randomizers.normal_choice,\n",
    "            trainer_kw = dict(total_variation_weight=120),\n",
    "            style_layers_selector_kw = dict(min_output_elements_num=2, rel_loc=0.05, rel_scale=0.25), \n",
    "            content_layers_selector_kw = dict(rel_loc=0.5, rel_scale=0.26)\n",
    "        )\n",
    "    trainer.compile(tf.keras.optimizers.Adam(learning_rate=0.02, beta_1=0.99, epsilon=1e-1))\n",
    "    trainers.append(trainer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Job of `TraintersSelectioner` is to pick most interesting `trainers` for you. It has implemented methods that allow its to train trainers images, sort them by given criteria or remove the most \"boring\" ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectioner = src.selectioner.TraintersSelectioner(trainers)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can provide callbacks that will be called after every trainer finish his training. There are two predefined callbacks `clear_output()` which is method imported from `IPython` that clear output in running cell and `plot_trainers()` - that will plot all trainers that are currently stored in `selectioner`. Callbacks will be called in the same order as they were provided, so clear_output will erase output from previous trainer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_trainters():\n",
    "    src.vizualization.plot_trained_images(selectioner.trainers)\n",
    "    plt.show()\n",
    "\n",
    "callbacks = [clear_output, plot_trainters]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a core of generation process.  \n",
    "- `train()` method will run training for every trainer. Trainers will apply gradient to image `epochs*steps` times.  \n",
    "- After training history will be saved, so if selectioner removes trainer that is interesting for you, you will be able get back to them later.\n",
    "- `sort_trainers_by_differences()` applies `ordering_method` to all pairs of trained images, and averages results per trainer. After that it sorts trainers in descending order, based on those averages. `sewar.full_ref.mse` (ordering method) measures similarity of images, so after sorting images that are the most different from all other will be on the top, and the least on the bottom.\n",
    "- `remove_second_half_trainers()` does what it says. In this case removes trainers that are the most similar to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "selectioner.train(epochs=1, steps=30, callbacks=callbacks)\n",
    "selectioner.save_history()\n",
    "selectioner.sort_trainers_by_differences(sewar.full_ref.mse)\n",
    "clear_output()\n",
    "src.vizualization.plot_trained_images(selectioner.trainers)\n",
    "selectioner.remove_second_half_trainers()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procedure defined above will be repeated two times in cells bellow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "selectioner.train(epochs=1, steps=30, callbacks=callbacks)\n",
    "selectioner.save_history()\n",
    "selectioner.sort_trainers_by_differences(sewar.full_ref.mse)\n",
    "clear_output()\n",
    "src.vizualization.plot_trained_images(selectioner.trainers)\n",
    "selectioner.remove_second_half_trainers()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After last selection process only four trainers remains. If you are happy with the results, you can save one of the trainers generations few cells below. If not, before \"saving cell\" there are some that allow you to train specified trainer longer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectioner.train(epochs=1, steps=30, callbacks=callbacks)\n",
    "selectioner.save_history()\n",
    "selectioner.sort_trainers_by_differences(sewar.full_ref.mse)\n",
    "clear_output()\n",
    "src.vizualization.plot_trained_images(selectioner.trainers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False, \"Exectution stopped on this cell, to allow you manually train selected images.\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition of callbacks, similar to selectioner ones, but designed to work with single trainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_output_image():\n",
    "    display(trainer.output_image) \n",
    "trainer_callbacks = [clear_output, display_output_image]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can pick one of the trainers (in this example third one), and train it little bit longer. After every epoch callbacks will be called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = selectioner.trainers[2]\n",
    "trainer.training_loop(epochs=4, steps_per_epoch=30, callbacks=trainer_callbacks)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`plot_trainer()` will produce plot that summarize trainer - it contains:\n",
    "- Style and content images that were used to define loss function.\n",
    "- Output image that trainer generated.\n",
    "- Model schema with layers used in training marked on it. Styles layers marked on blue and content layers marked on red (if content layer is also style layer, then it has blue interior with red border)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src.vizualization.plot_trainer(selectioner.trainers[2])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`save_vizualizations()` will save two images:\n",
    "- raw generated image that will be stored in `./images/results` folder\n",
    "- output generated by `plot_trainer()` function stored in `./images/trainers`  \n",
    "\n",
    "Both images share the same generated name, that is combination of style and content images names. If there is already image with this name stored, then unique postfix will be added to new name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src.vizualization.save_vizualizations(\n",
    "    selectioner.trainers[3],\n",
    "    style_image_path,\n",
    "    content_image_path,\n",
    "    BASE_RESULT_PATH,\n",
    "    BASE_TRAINER_PATH\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to come back to any of removed trainers you can do that uncommenting this cell. `selectioner.history[0][5]` will return six selectioner from first save.  \n",
    "Similarly if you want to pick fourth selectioner from second save you should change this line to `selectioner.history[1][3]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ HISTORY TRAINING #######################\n",
    "# You can uncomment that if you want return to some trainers discarded in selection process.\n",
    "\n",
    "# trainer = selectioner.history[0][5]\n",
    "# trainer.training_loop(30, 4, callbacks=trainer_callbacks)\n",
    "\n",
    "# src.vizualization.save_vizualizations(\n",
    "#     trainer,\n",
    "#     style_image_path,\n",
    "#     content_image_path,\n",
    "#     BASE_RESULT_PATH,\n",
    "#     BASE_TRAINER_PATH\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src.vizualization.plot_trainer(selectioner.trainers[0])\n",
    "selectioner.trainers[0].style_layers, selectioner.trainers[0].content_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src.vizualization.plot_trainer(selectioner.trainers[1])\n",
    "selectioner.trainers[1].style_layers, selectioner.trainers[1].content_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src.vizualization.plot_trainer(selectioner.trainers[2])\n",
    "selectioner.trainers[2].style_layers, selectioner.trainers[2].content_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src.vizualization.plot_trainer(selectioner.trainers[3])\n",
    "selectioner.trainers[3].style_layers, selectioner.trainers[3].content_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8dabb8392f1555fe283b7ab03fc571d8a39785f5bda47a817e5da987f795bf2a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
